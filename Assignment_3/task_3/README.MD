# Assignment 3 - Task 3 (CUDA): Coalesced vs Non-coalesced Global Memory Access (N = 1,000,000)

В этом задании реализована CUDA-программа для обработки массива, демонстрирующая
разницу между **коалесцированным** и **некоалесцированным** доступом к **глобальной памяти GPU**.
Цель — сравнить время выполнения обеих реализаций для массива размера **N = 1 000 000** элементов.

## Цель работы

- Реализовать две версии CUDA-ядра для обработки массива:
  1) с **коалесцированным** доступом к глобальной памяти;
  2) с **некоалесцированным** доступом к глобальной памяти.
- Измерить время выполнения обеих версий на одном и том же размере входных данных.
- Сравнить производительность и сделать вывод.

## Ключевые определения (кратко)

### Коалесцированный доступ (coalesced)
Доступ считается коалесцированным, когда потоки одного warp (32 потока) обращаются к
**соседним адресам** памяти (например, `in[idx]`), поэтому GPU может объединить запросы
в минимальное число транзакций памяти.

### Некоалесцированный доступ (non-coalesced)
Некоалесцированный доступ возникает, когда потоки warp обращаются к **разрозненным**
адресам (например, со stride/перестановкой индексов). Это приводит к большому числу
памятных транзакций и заметному росту задержек доступа.

## Реализация

### 1) Coalesced kernel (линейный доступ)
Каждый поток обрабатывает свой индекс:
- thread `idx` читает `in[idx]` и пишет `out[idx]`.

Типовой шаблон: out[idx] = in[idx] * 2


### 2) Non-coalesced kernel (strided access)
Используется намеренно “плохой” паттерн:
- thread `idx` обращается к элементу `(idx * stride) % N`.
В результате соседние потоки обращаются к несоседним адресам, что разрушает коалесцирование.

## Параметры эксперимента

- Размер массива: `N = 1 000 000`
- Размер блока: `Block = 256`
- Размер сетки: `Grid = 3907`
- Количество запусков для усреднения: `iters = 300`
- Тайминг: `cudaEvent` (среднее время на один запуск ядра)
- Проверка корректности: сравнение с CPU-референсом по `Max abs error` (`EPS = 1e-4`)

## Результаты (полученные измерения)

Фактический вывод программы:
Assignment 3 - Task 3 (CUDA): Coalesced vs Non-coalesced
N = 1000000, Block = 256, Grid = 3907
Coalesced access avg time (ms) = 0.037918
Non-coalesced access avg time (ms) = 0.860201
Slowdown (non/coalesced) = 22.686031
Max abs error = 0.000000
Correct = YES

### Таблица результатов
| Access pattern        | Avg kernel time (ms) |
|----------------------|----------------------:|
| Coalesced            | 0.037918              |
| Non-coalesced        | 0.860201              |
| Slowdown (non/coal)  | 22.686×               |

## Интерпретация результатов

Коалесцированный доступ оказался значительно быстрее, потому что GPU способен
агрегировать обращения потоков warp к последовательным адресам памяти и выполнять их
меньшим числом транзакций. В некоалесцированном варианте потоки обращаются к
разрозненным адресам, из-за чего увеличивается количество транзакций и растёт латентность,
что приводит к резкому замедлению.

В данном эксперименте разница составила **≈ 22.69×**, что наглядно демонстрирует,
что для задач, ограниченных пропускной способностью памяти, паттерн доступа к памяти
является критически важным фактором производительности.

## Проверка корректности

Корректность подтверждена:
- `Max abs error = 0.000000`
- `Correct = YES`

## Вывод

Эксперимент показал, что **коалесцированный доступ к глобальной памяти** существенно
повышает производительность CUDA-программ. Некоалесцированный доступ приводит к
кратному замедлению (в данном случае **≈ 22.69×**) даже для простой поэлементной операции.
Поэтому при разработке CUDA-ядер важно организовывать данные и индексацию так,
чтобы соседние потоки обращались к соседним адресам памяти.
