# Assignment 3 - Архитектура GPU и оптимизация CUDA-программ

Данный Assignment посвящён изучению **архитектуры GPU** и ключевых приёмов
**оптимизации CUDA-программ**, связанных с организацией вычислений и доступом
к памяти. В ходе работы были реализованы и экспериментально исследованы несколько
CUDA-программ, демонстрирующих влияние различных архитектурных факторов GPU
на производительность.

Основной акцент сделан на:
- иерархию памяти CUDA,
- шаблоны доступа к глобальной памяти,
- использование разделяемой памяти,
- влияние размера блока потоков,
- подбор оптимальной конфигурации запуска CUDA-ядер.

## Состав Assignment 3
### **Task 1 - Global memory vs Shared memory**
Реализована CUDA-программа для поэлементного умножения массива на скаляр:
- версия с использованием **только глобальной памяти**;
- версия с использованием **разделяемой памяти (shared memory)**.

Проведено сравнение времени выполнения для массива размером `N = 1 000 000`.
Показано, что для element-wise операций shared memory не даёт ускорения из-за
отсутствия повторного использования данных и дополнительных накладных расходов
на синхронизацию.

### **Task 2 - Влияние размера блока потоков**
Реализована CUDA-программа для поэлементного сложения двух массивов.
Проведены замеры времени выполнения CUDA-ядра для нескольких размеров блока
потоков (128, 256, 512, 1024).

Эксперимент показал, что:
- размер блока влияет на производительность,
- оптимальным для данной задачи оказался блок из **256 потоков**.

### **Task 3 - Coalesced vs Non-coalesced memory access**
Реализованы две версии CUDA-ядра:
- с **коалесцированным доступом** к глобальной памяти;
- с **некоалесцированным доступом** (strided access).

Для массива `N = 1 000 000` показано, что некоалесцированный доступ приводит
к **кратному замедлению** (в эксперименте ≈22×), что подчёркивает критическую
важность правильного шаблона доступа к памяти.

### **Task 4 - Оптимизация конфигурации сетки и блоков**
Для программы из Task 2 выполнен подбор оптимальных параметров запуска:
- сравнение **неоптимальной конфигурации** (block = 1024),
- поиск **оптимальной конфигурации** среди нескольких размеров блока.

Показано, что оптимизация параметров block/grid даёт измеримый выигрыш
в производительности и является важным этапом CUDA-оптимизации.

## Контрольные вопросы к Assignment 3

### **1. Какие основные типы памяти существуют в архитектуре CUDA и чем они отличаются по скорости доступа?**
В архитектуре CUDA используются следующие основные типы памяти:
- **Регистры** - самая быстрая память, локальная для каждого потока.
- **Разделяемая память (shared memory)** - быстрая память, общая для потоков одного блока.
- **Глобальная память** - большая по объёму, но с высокой задержкой доступа.
- **Константная память** - кэшируемая память только для чтения.
- **Текстурная память** - оптимизирована для пространственно локальных обращений.

По скорости доступа:  
`Регистры > Shared > Константная/Текстурная > Глобальная`.

### **2. В каких случаях использование разделяемой памяти позволяет ускорить выполнение CUDA-программы?**
Разделяемая память эффективна, когда:
- данные **многократно используются** потоками одного блока;
- необходимо уменьшить количество обращений к глобальной памяти;
- алгоритм позволяет организовать **tiling** (например, умножение матриц).

Для простых element-wise операций shared memory обычно не даёт ускорения.

### **3. Как шаблон доступа к глобальной памяти влияет на производительность GPU-программы?**
Шаблон доступа определяет, могут ли обращения потоков warp быть
**коалесцированы**:
- при коалесцированном доступе несколько обращений объединяются в одну
  транзакцию памяти;
- при некоалесцированном доступе требуется множество разрозненных транзакций.

Некоалесцированный доступ резко снижает производительность.

### **4. Почему одинаковый алгоритм на GPU может показывать разное время выполнения при разных способах обращения к памяти?**
Потому что:
- задержки доступа к памяти доминируют над вычислениями;
- разные шаблоны доступа приводят к разному числу транзакций памяти;
- эффективность использования кэшей и пропускной способности памяти меняется.

Даже при одинаковом числе операций время может отличаться на порядок.

### **5. Как размер блока потоков влияет на производительность CUDA-ядра?**
Размер блока влияет на:
- **occupancy** (число активных потоков на SM),
- использование регистров и shared memory,
- эффективность планирования warp.
Слишком маленькие блоки не загружают GPU полностью, слишком большие -
ограничивают число активных блоков. Обычно оптимальный диапазон - **128-512 потоков**.

### **6. Что такое варп и почему важно учитывать его при разработке CUDA-программ?**
**Варп (warp)** - это группа из **32 потоков**, которые выполняются
синхронно по модели SIMD.

Важно учитывать warp, потому что:
- расхождение ветвлений внутри warp снижает производительность;
- коалесцирование памяти происходит на уровне warp;
- оптимальный размер блока обычно кратен 32.

### **7. Какие факторы необходимо учитывать при выборе конфигурации сетки и блоков потоков?**
При выборе конфигурации необходимо учитывать:
- размер задачи (N),
- архитектуру GPU (число SM, warp size),
- использование регистров и shared memory,
- occupancy,
- характер доступа к памяти.

Оптимальная конфигурация зависит от конкретного алгоритма.

### **8. Почему оптимизация CUDA-программы часто начинается с анализа работы с памятью, а не с изменения алгоритма?**
Потому что большинство CUDA-программ:
- **ограничены пропускной способностью памяти**, а не вычислениями;
- тратят основное время на доступ к глобальной памяти.

Оптимизация доступа к памяти (коалесцирование, shared memory, кэширование)
часто даёт больший эффект, чем усложнение алгоритма.

## Итог
Assignment 3 на практике продемонстрировал, что высокая производительность
CUDA-программ достигается не только за счёт параллелизма, но и за счёт
грамотного использования архитектурных особенностей GPU: иерархии памяти,
warp-исполнения и параметров запуска вычислений.
