# Лабораторная работа 7 — Анализ параллельных алгоритмов на CUDA  
## Редукция, префиксная сумма и анализ производительности

В данной лабораторной работе реализованы и исследованы три взаимосвязанных задания, посвящённых базовым параллельным алгоритмам на GPU с использованием CUDA:
- **7.1 — Редукция (sum)**
- **7.2 — Префиксная сумма (scan)**
- **7.3 — Анализ производительности и оптимизация**

Основная цель работы — изучить поведение алгоритмов при увеличении размера входных данных, сравнить CPU и GPU реализации и показать влияние использования различных типов памяти CUDA.

---

## Задание 7.1 — Редукция

### Краткое описание  
Реализована операция редукции (суммирование элементов массива) на GPU.  
Алгоритм использует **shared memory** и многошаговую редукцию, где каждый блок вычисляет частичную сумму, а затем эти суммы сворачиваются до одного значения.

### Основные результаты  
- Для малых массивов (N = 1024) CPU быстрее из-за накладных расходов на запуск CUDA.
- Для больших массивов GPU-реализация значительно превосходит CPU.
- Абсолютная ошибка увеличивается с ростом N из-за использования типа `float`, но относительная ошибка остаётся близкой к нулю.

---

## Задание 7.2 — Префиксная сумма

### Краткое описание  
Реализована **inclusive prefix sum (scan)** на GPU.  
Алгоритм состоит из двух этапов:
1. Вычисление префиксной суммы внутри каждого блока (shared memory).
2. Рекурсивное сканирование сумм блоков и добавление оффсетов.

Использован алгоритм **Blelloch scan**.

### Основные результаты  
- Время выполнения растёт с увеличением размера массива, что соответствует ожидаемой асимптотике.
- Абсолютная ошибка увеличивается при больших N из-за накопления ошибок округления.
- GPU эффективно обрабатывает большие массивы по сравнению с CPU.

---

## Задание 7.3 — Анализ производительности

### Что сравнивалось  
**Редукция:**
- CPU (последовательная)
- GPU с `atomicAdd` (глобальная память)
- GPU с использованием shared memory

**Сканирование:**
- CPU
- GPU Hillis–Steele
- GPU Blelloch

### Основные наблюдения  
- Редукция через `atomicAdd` в глобальной памяти является самым медленным и наименее масштабируемым вариантом.
- Использование **shared memory** даёт ускорение на порядок и более по сравнению с CPU для больших массивов.
- Для сканирования алгоритм Hillis–Steele оказался быстрее Blelloch в данной реализации на больших N из-за меньших накладных расходов.
- GPU выигрывает у CPU только начиная с достаточно больших размеров массива, где накладные расходы окупаются.

---

## Общий анализ результатов
- GPU наиболее эффективен при обработке **больших объёмов данных**.
- Для малых массивов CPU может быть быстрее.
- Ключевым фактором ускорения является использование **shared memory** и уменьшение обращений к глобальной памяти.
- Рост абсолютной ошибки является ожидаемым следствием вычислений в `float` и различного порядка суммирования.

---

## Рекомендации по оптимизации
- Использовать **shared memory** для редукции и сканирования вместо глобальной памяти.
- Избегать `atomicAdd` для массовых операций суммирования.
- Выбирать алгоритм сканирования в зависимости от архитектуры и размера данных.
- Для повышения точности использовать `double` или компенсированное суммирование (Kahan).
- Минимизировать количество запусков ядер и синхронизаций.
- Для больших объёмов данных использовать **pinned memory** для ускорения копирования Host ↔ Device.

---

## Контрольные вопросы

### 1. В чём разница между редукцией и сканированием?  
Редукция сводит массив к **одному значению** (например, сумма),  
а сканирование вычисляет **промежуточные результаты** (префиксные суммы) для каждого элемента массива.

### 2. Какие типы памяти CUDA используются для оптимизации редукции и сканирования?  
Основные типы:
- **Shared memory** — для быстрых операций внутри блока.
- **Глобальная память** — для хранения входных и выходных данных.
- **Регистры** — для локальных временных переменных потоков.

### 3. Как можно оптимизировать префиксную сумму на GPU?  
- Использовать shared memory.
- Применять алгоритмы с меньшим числом синхронизаций (например, Blelloch).
- Минимизировать количество проходов по данным.
- Использовать оптимальный размер блока и выравнивание данных.

### 4. Приведите пример задачи, где применяется сканирование.  
Префиксная сумма используется в:
- построении гистограмм,
- алгоритмах сортировки (radix sort),
- параллельной фильтрации массивов,
- вычислении cumulative sum в аналитике данных.

---

## Вывод  
В ходе лабораторной работы были изучены ключевые параллельные алгоритмы CUDA — редукция и префиксная сумма.  
Эксперименты показали, что грамотное использование памяти и алгоритмов позволяет добиться значительного ускорения вычислений на GPU по сравнению с CPU.
