# Задание 2. Оптимизация доступа к памяти на GPU (CUDA)

В данной работе исследуется влияние **паттернов доступа к памяти** на производительность CUDA-программы.  
Реализованы несколько версий CUDA-ядер для обработки массива данных и выполнено сравнение времени их выполнения.

## Цель работы
- изучить влияние коалесцированного и некоалесцированного доступа к глобальной памяти;
- измерить время выполнения CUDA-ядер с использованием `cudaEvent`;
- проанализировать эффект использования разделяемой памяти;
- сделать выводы о роли доступа к памяти в производительности GPU-программ.

## Описание реализации
В программе реализованы три версии CUDA-ядра:
1. **Коалесцированный доступ к глобальной памяти**  
   Потоки обращаются к последовательным элементам массива, что позволяет GPU объединять обращения к памяти.
2. **Некоалесцированный доступ к памяти**  
   Потоки обращаются к элементам массива с шагом, отличным от единицы, что моделирует менее эффективный паттерн доступа.
3. **Использование разделяемой памяти (shared memory)**  
   Данные сначала загружаются из глобальной памяти в разделяемую, после чего используются потоками внутри блока.
Для всех версий выполняется одинаковая операция обработки массива, что позволяет корректно сравнивать производительность.

## Измерение времени выполнения
Время выполнения ядер измеряется с помощью **CUDA events (`cudaEventRecord`, `cudaEventElapsedTime`)**, что позволяет получить точное время работы GPU-кода без учёта инициализации.

## Результаты и анализ
Эксперимент показал, что при малом шаге доступа к памяти различие между коалесцированным и некоалесцированным доступом выражено слабо. Это связано с эффективной работой кешей GPU и возможностью объединения обращений к памяти.
Использование разделяемой памяти в данной задаче не привело к заметному ускорению, поскольку каждый элемент данных используется только одним потоком и не переиспользуется внутри блока.

## Вывод
- Производительность CUDA-программ существенно зависит от способа обращения к памяти.
- Коалесцированный доступ к глобальной памяти является предпочтительным паттерном.
- Эффект от использования shared memory проявляется только при повторном использовании данных потоками.
- При простых операциях и малых шагах доступа влияние паттернов памяти может быть слабо выражено.

## Используемые технологии
- **C++**
- **CUDA**
- **cudaEvent** для измерения времени выполнения
