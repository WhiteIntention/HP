# Assignment 4 - Task 2 (25 pts)
## Префиксная сумма (Scan) на CUDA с использованием shared memory + сравнение с CPU (N = 1 000 000)

В этом задании реализована **префиксная сумма (inclusive scan)** массива:
- **последовательная реализация на CPU** (baseline),
- **CUDA-реализация на GPU** с использованием **разделяемой памяти (shared memory)**.

Размер массива по заданию: **N = 1 000 000**.

## CUDA-реализация (shared memory)
Реализация сделана в 3 этапа (классический подход для больших массивов):

1) **Scan внутри каждого блока (exclusive) + сумма блока**
- каждый блок обрабатывает `2 * BLOCK` элементов;
- используется shared memory;
- сохраняется сумма каждого блока в массив `block_sums[]`.

2) **Scan массива сумм блоков**
- массив `block_sums[]` маленький, поэтому сканируется в одном блоке;
- результат — `block_offsets[]` (exclusive-оффсеты для блоков).

3) **Добавление оффсетов + переход к inclusive**
- каждому элементу добавляется оффсет его блока;
- чтобы получить inclusive scan:
out_incl[i] = out_excl[i] + offset + in[i]

## Параметры эксперимента
- `N = 1 000 000`
- `BLOCK = 512` (каждый блок обрабатывает `2 * BLOCK = 1024` элементов)
- число блоков: numBlocks = ceil(N / 1024) = 977
- измерение GPU-времени: **cudaEvent**, усреднение по **50 запускам**
- измерение CPU-времени: `std::chrono`
- тип данных: **int** (чтобы проверка была строгой и без ошибок округления)

## Результаты (фактический вывод)
Assignment 4 - Task 2: Prefix Sum (Scan) using Shared Memory
N = 1000000
CPU time (ms) = 0.684932
GPU time (ms) = 0.269911 (avg over 50 runs, kernels only)
Speedup = 2.537621x
Max diff = 0
Correct = YES


---

## Анализ результатов

### Корректность
Результаты CPU и GPU полностью совпали:
- `Max diff = 0`
- `Correct = YES`
Это стало возможным благодаря использованию целого типа данных (`int`), где результат не зависит от порядка сложения (в отличие от `float`).

### Производительность
GPU-реализация оказалась быстрее CPU:
- CPU: `0.684932 ms`
- GPU: `0.269911 ms`

Ускорение:
- `Speedup = 2.537621×`

GPU выигрывает за счёт:
- параллельного суммирования внутри блоков,
- быстрого доступа к shared memory,
- уменьшения обращений к глобальной памяти при редукции внутри блока.

## Вывод
CUDA-реализация префиксной суммы с использованием shared memory обеспечивает корректный результат и даёт ускорение **≈2.54×** по сравнению с последовательной реализацией на CPU для массива `N = 1 000 000`.  
Эксперимент подтверждает, что для задач типа scan/reduction использование shared memory и иерархического подхода (scan по блокам + оффсеты) существенно улучшает производительность по сравнению с последовательным вычислением.
