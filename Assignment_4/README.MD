# Assignment 4 - Task 1
## CUDA Sum (Global Memory) vs Sequential CPU Sum - N = 100,000

В этом задании реализована программа для вычисления суммы элементов массива:
- **последовательная реализация на CPU** (baseline);
- **CUDA-реализация на GPU** с использованием **глобальной памяти** и атомарного сложения `atomicAdd`.

Цель: сравнить **результат** и **время выполнения** для массива размера **N = 100 000** элементов.

## Краткое описание реализации

### CPU (последовательно)
Сумма вычисляется простым циклом:

Время измеряется с помощью `std::chrono`.

### CUDA (global memory + atomicAdd)
Каждый поток читает `data[idx]` из глобальной памяти и добавляет значение в общую переменную результата:
atomicAdd(result, data[idx])
Время ядра измеряется с помощью `cudaEvent`.

## Параметры эксперимента
- Размер массива: `N = 100 000`
- Тип данных: `float`
- Размер блока: `256`
- Grid: `ceil(N / 256)`
- Генерация входных данных: случайные `float` в диапазоне `[0, 1]`
- Измерение времени:
  - CPU: `std::chrono` (ms)
  - GPU: `cudaEventElapsedTime` (ms)

## Результаты (фактический вывод)
Assignment 4 - Task 1: Array Sum (CPU vs CUDA)
N = 100000
CPU sum = 50162.511719
GPU sum = 50162.617188
CPU time (ms) = 0.164144
GPU time (ms) = 0.358432
Difference = 0.105469

## Анализ результата и времени
### Корректность
Значения суммы на CPU и GPU близки, но не совпадают идеально:
- `Difference = 0.105469`

Это нормально, потому что:
- на CPU и GPU **разный порядок суммирования**,
- при использовании `float` и `atomicAdd` возникают накопленные ошибки округления,
- операции суммирования в плавающей точке **неассоциативны**.

### Производительность
В данном эксперименте GPU оказался медленнее CPU:
- CPU: `0.164 ms`
- GPU: `0.358 ms`

Причины:
1) **Накладные расходы запуска ядра** заметны при малом N (100k).
2) `atomicAdd` по одной общей переменной вызывает **сериализацию** (много потоков конкурируют за один адрес памяти).
3) Для редукции (sum) более эффективны иерархические методы (reduction) через shared memory, а не атомики.

## Вывод
CUDA-версия с использованием глобальной памяти и `atomicAdd` корректно вычисляет сумму массива, но при размере **N = 100 000** показывает худшую производительность по сравнению с последовательной CPU-реализацией. Это объясняется накладными расходами запуска CUDA и высокой стоимостью атомарных операций. Для ускорения на GPU рекомендуется применять параллельную редукцию (block reduction) с использованием shared memory.
