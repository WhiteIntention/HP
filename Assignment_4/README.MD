# Assignment 4  
## Тема: Гибридные и распределённые параллельные вычисления

Assignment 4 посвящён изучению **разных моделей параллельных вычислений** и сравнению их концепций: последовательных, GPU-ускоренных, гибридных и распределённых. 
Все задания выполнены на языке **C++** с использованием **CUDA** и **MPI**.

## Структура Assignment 4

### Task 1 - Сумма элементов массива (CPU vs CUDA)
**Идея:**  
Сравнить последовательную реализацию на CPU и параллельную реализацию на GPU.  
Задание демонстрирует, что не каждая задача автоматически выигрывает от переноса на GPU, особенно при небольшом размере данных и простой операции.

### Task 2 - Префиксная сумма (Scan) с использованием shared memory
**Идея:**  
Показать, как использование **разделяемой памяти GPU** и иерархического подхода (обработка по блокам) позволяет ускорить сложные операции, такие как префиксная сумма, по сравнению с последовательным CPU-алгоритмом.

### Task 3 - Гибридная программа CPU + GPU
**Идея:**  
Реализовать гибридную модель, в которой **CPU и GPU работают параллельно** над разными частями массива.  
Задание иллюстрирует, что гибридные вычисления эффективны только при правильном балансе между вычислениями и затратами на передачу данных.

### Task 4 - Распределённая обработка массива с использованием MPI
**Идея:**  
Продемонстрировать принципы **распределённых вычислений**:
- разделение данных между процессами,
- локальные вычисления,
- сбор результатов.  
Задание показывает влияние межпроцессных коммуникаций и подчёркивает, что MPI даёт наибольший эффект при работе на нескольких физических узлах.

## Общая идея Assignment 4
Assignment 4 показывает, что:
- выбор модели параллелизма (CPU, GPU, Hybrid, MPI) должен основываться на характере задачи,
- ускорение зависит не только от числа потоков или процессов, но и от архитектурных особенностей и накладных расходов,
- оптимизация параллельных программ требует понимания взаимодействия вычислений и памяти.

Контрольные вопросы к Assignment 4:
### 1. В чём отличие гибридных вычислений от вычислений только на CPU или GPU?
Гибридные вычисления используют одновременно CPU и GPU, распределяя задачу между ними, в отличие от выполнения всей задачи только на одном устройстве.
### 2. Для каких задач целесообразно распределять вычисления между CPU и GPU?
Для задач с большим объёмом данных, высокой вычислительной сложностью и возможностью параллельной обработки.
### 3. В чём разница между синхронной и асинхронной передачей данных CPU–GPU?
Синхронная передача блокирует CPU до завершения копирования, асинхронная — позволяет выполнять вычисления параллельно с передачей данных.
### 4. Почему асинхронная передача данных повышает производительность?
Она уменьшает простои, перекрывая вычисления и передачу данных.
### 5. Какие функции MPI используются для распределения и сбора данных?
MPI_Scatter(v), MPI_Gather(v), MPI_Bcast, MPI_Reduce.
### 6. Как число MPI-процессов влияет на время выполнения?
Рост числа процессов снижает время вычислений, но увеличивает накладные расходы на обмен данными.
### 7. Что ограничивает масштабируемость распределённых программ?
Коммуникационные затраты, неравномерная нагрузка и аппаратные ограничения.
### 8. Когда распределённые вычисления эффективны, а когда нет?
Эффективны для больших и сложных задач; неэффективны для маленьких и простых из-за накладных расходов.
