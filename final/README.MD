# Final Assignment — FIR-фильтр на CPU (seq + OpenMP) и GPU (CUDA)

## Цель работы
Реализовать FIR-фильтрацию как 1D-свёртку сигнала `x` с фильтром `h` длины `K`:

\[
y[i] = \sum_{j=0}^{K-1} h[j]\cdot x[i-j],\quad \text{если } i-j<0 \Rightarrow x[i-j]=0
\]

Сделать:
1) CPU-версию (последовательно)  
2) CPU-версию с OpenMP (параллельно по выходным элементам)  
3) CUDA-версию (ядро по индексу выходного сигнала)  
4) Эксперименты для разных `N` и `K`, сравнение времени и проверка корректности (max abs error)

---

## Реализация

### CPU (последовательно)
- вычисление эталона `y_ref`
- суммирование выполняется в `double` (для более стабильного сравнения), результат сохраняется в `float`

### CPU (OpenMP)
- параллелизация по `i` (каждый поток считает свой `y[i]`)
- используется директива `#pragma omp parallel for`

### GPU (CUDA)
- один поток вычисляет один элемент `y[i]`
- коэффициенты фильтра `h` копируются в `__constant__` память (`cudaMemcpyToSymbol`)
- измеряются отдельно:
  - `H2D` (копирование `x` на устройство)
  - `kernel` (время ядра)
  - `D2H` (копирование `y` обратно)
  - `total = H2D + kernel + D2H`

---

## Корректность
Качество проверялось как:

- `max abs error = max_i |y_gpu[i] - y_ref[i]|`

Ошибки находятся на уровне `~1e-6 … 2e-6` (или 0 в печати), что ожидаемо, потому что:
- CPU эталон аккумулирует сумму в `double`
- GPU считает в `float`
- порядок суммирования на CPU и GPU отличается

---

## Эксперименты
Размеры сигналов:
- `N = 1 000 000`
- `N = 10 000 000`
- `N = 50 000 000`

Длины фильтра:
- `K = 15, 31, 63, 127, 255`

---

## Результаты (лог выполнения)

### K = 15
**N = 1 000 000**  
CPU seq = 33.232 ms  
CPU omp = 42.226 ms, err = 0.000000  
GPU total = 6.113 ms (H2D 2.955 + kernel 0.164 + D2H 2.994), err = 0.000000  

**N = 10 000 000**  
CPU seq = 356.104 ms  
CPU omp = 416.999 ms, err = 0.000000  
GPU total = 28.257 ms (H2D 17.466 + kernel 0.831 + D2H 9.960), err = 0.000000  

**N = 50 000 000**  
CPU seq = 883.494 ms  
CPU omp = 1031.640 ms, err = 0.000000  
GPU total = 91.651 ms (H2D 42.850 + kernel 4.025 + D2H 44.776), err = 0.000000  

---

### K = 31
**N = 1 000 000**  
CPU seq = 34.350 ms  
CPU omp = 37.985 ms, err = 0.000000  
GPU total = 2.014 ms (H2D 0.871 + kernel 0.154 + D2H 0.989), err = 0.000000  

**N = 10 000 000**  
CPU seq = 361.362 ms  
CPU omp = 389.505 ms, err = 0.000000  
GPU total = 18.548 ms (H2D 8.615 + kernel 1.341 + D2H 8.592), err = 0.000000  

**N = 50 000 000**  
CPU seq = 1810.369 ms  
CPU omp = 1969.034 ms, err = 0.000000  
GPU total = 93.638 ms (H2D 43.207 + kernel 6.602 + D2H 43.829), err = 0.000000  

---

### K = 63
**N = 1 000 000**  
CPU seq = 70.560 ms  
CPU omp = 75.886 ms, err = 0.000000  
GPU total = 2.125 ms (H2D 0.848 + kernel 0.267 + D2H 1.010), err = 0.000000  

**N = 10 000 000**  
CPU seq = 749.031 ms  
CPU omp = 820.581 ms, err = 0.000000  
GPU total = 24.068 ms (H2D 12.383 + kernel 2.417 + D2H 9.268), err = 0.000000  

**N = 50 000 000**  
CPU seq = 4057.683 ms  
CPU omp = 3866.740 ms, err = 0.000000  
GPU total = 99.762 ms (H2D 43.000 + kernel 11.975 + D2H 44.787), err ≈ 0.000001  

---

### K = 127
**N = 1 000 000**  
CPU seq = 158.683 ms  
CPU omp = 155.622 ms, err = 0.000000  
GPU total = 2.458 ms (H2D 0.932 + kernel 0.490 + D2H 1.036), err ≈ 0.000001  

**N = 10 000 000**  
CPU seq = 1625.564 ms  
CPU omp = 2208.042 ms, err = 0.000000  
GPU total = 30.655 ms (H2D 16.859 + kernel 4.641 + D2H 9.155), err ≈ 0.000001  

**N = 50 000 000**  
CPU seq = 8151.514 ms  
CPU omp = 8853.510 ms, err = 0.000000  
GPU total = 111.521 ms (H2D 43.738 + kernel 23.084 + D2H 44.698), err ≈ 0.000001  

---

### K = 255
**N = 1 000 000**  
CPU seq = 325.163 ms  
CPU omp = 323.678 ms, err = 0.000000  
GPU total = 2.922 ms (H2D 0.941 + kernel 0.948 + D2H 1.032), err ≈ 0.000002  

**N = 10 000 000**  
CPU seq = 3325.111 ms  
CPU omp = 4163.335 ms, err = 0.000000  
GPU total = 29.925 ms (H2D 12.008 + kernel 9.173 + D2H 8.744), err ≈ 0.000002  

**N = 50 000 000**  
CPU seq = 17337.976 ms  
CPU omp = 16302.399 ms, err = 0.000000  
GPU total = 133.716 ms (H2D 43.376 + kernel 45.713 + D2H 44.627), err ≈ 0.000002  

---

## Анализ результатов

### 1) GPU даёт сильное ускорение
GPU-версия существенно быстрее CPU практически во всех конфигурациях.
На больших `N` разница становится очень большой из-за высокой параллельности на GPU.

### 2) Время GPU total ограничено передачей данных
Во многих измерениях видно, что:
- `kernel` занимает миллисекунды или доли миллисекунды
- основная часть `GPU total` — это `H2D + D2H`

Вывод: GPU особенно выгоден, когда данные остаются на устройстве и используются в дальнейших этапах пайплайна (без постоянного копирования обратно).

### 3) OpenMP не всегда ускоряет CPU
При небольших `K` и ограниченном числе потоков ускорение OpenMP может быть небольшим или даже отрицательным из-за накладных расходов и ограничений по памяти/кэшу.
При более тяжёлых конфигурациях эффект может улучшаться, но зависит от железа и настроек.
