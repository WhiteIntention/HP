# OpenCL Vector Add (C++): сравнение CPU и GPU для двух сценариев (1M и 10M) с итоговым графиком

Данный проект представляет собой программу на **C++**, использующую **OpenCL 1.2** для выполнения поэлементного сложения двух массивов (`C[i] = A[i] + B[i]`) и анализа производительности вычислений на **GPU** и **CPU**.  
Код программы написан на C++, при этом вычислительное ядро (`kernel`) реализовано на языке **OpenCL C** и встроено в программу в виде строки `KERNEL_SRC`.

В рамках работы были выполнены **два различных сценария эксперимента**, отличающихся размером обрабатываемых данных:
- **Сценарий 1:** `N = 1 000 000` (1 миллион элементов)
- **Сценарий 2:** `N = 10 000 000` (10 миллионов элементов)

Для каждого сценария программа запускалась в двух режимах:
- выполнение на **GPU** (`gpu`),
- выполнение на **CPU** (`cpu`, при наличии OpenCL-платформы для CPU).

В конце эксперимента результаты сведены в таблицу и построен **график сравнения скорости выполнения**, наглядно показывающий различие производительности CPU и GPU при разных размерах данных.

## Описание проделанной работы

В начале работы программа генерирует два вектора `A` и `B` размера `N`, заполненных случайными целыми числами в диапазоне от 1 до 100. Далее на **CPU** вычисляется эталонный результат `Cref`, который используется для проверки корректности работы OpenCL-ядра.

После этого программа:
1. Находит доступные OpenCL-платформы.
2. Выбирает устройство в зависимости от режима запуска (`CPU` или `GPU`).
3. Создаёт OpenCL-контекст и очередь команд с включённым профилированием.
4. Компилирует kernel `vector_add`.
5. Создаёт буферы в памяти устройства и копирует в них входные данные.
6. Запускает kernel с глобальным размером `N`.
7. Считывает результат обратно в память хоста.
8. Измеряет:
   - **Kernel time** - время выполнения только OpenCL-ядра,
   - **Total time** - суммарное время выполнения участка (запуск kernel, ожидание завершения и чтение результата).
9. Сравнивает результат OpenCL с эталонным CPU-результатом и выводит корректность.

Все эти шаги выполняются отдельно для каждого сценария (`N = 1M` и `N = 10M`) и для каждого режима (CPU/GPU).

## Измеряемые показатели

В программе фиксируются два типа времени:
- **Kernel time (ms)** - время выполнения вычислений внутри OpenCL-ядра, измеряемое с помощью профайлинга событий OpenCL.
- **Total time (ms)** - общее время выполнения участка программы, включающее запуск ядра, ожидание его завершения и чтение результата обратно на host.

Важно отметить, что копирование входных массивов `A` и `B` на устройство выполняется при создании буферов (`CL_MEM_COPY_HOST_PTR`) и **не входит** в измерение `Total time`. Это сделано осознанно, чтобы отдельно оценить вычислительную часть алгоритма.

## Проведённые сценарии

### Сценарий 1: N = 1 000 000
В данном случае анализируется производительность при относительно небольшом объёме данных. Такой размер позволяет оценить влияние накладных расходов OpenCL и понять, насколько GPU эффективен при малых задачах.

### Сценарий 2: N = 10 000 000
Во втором сценарии размер данных увеличен в 10 раз. Это позволяет оценить масштабируемость решения и эффект параллельных вычислений, когда GPU может продемонстрировать существенный выигрыш по времени.

Для каждого сценария выполнялись запуски:
" ./Ass3_1 gpu "
" ./Ass3_1 cpu "

(при условии наличия OpenCL-платформы для CPU).

## Итоговый график сравнения

По результатам всех запусков была сформирована таблица времени выполнения для четырёх случаев:
- GPU, N = 1 000 000
- CPU, N = 1 000 000
- GPU, N = 10 000 000
- CPU, N = 10 000 000

На основе этих данных построен **график сравнения скорости решения**, где:
- по оси X отложены сценарии и режимы выполнения,
- по оси Y время выполнения в миллисекундах.

График наглядно демонстрирует, что при увеличении размера данных преимущество GPU становится более выраженным, тогда как при меньших размерах выигрыш может быть частично нивелирован накладными расходами.

## Проверка корректности

Корректность вычислений проверяется путём сравнения каждого элемента результирующего массива `C`, полученного с помощью OpenCL, с эталонным массивом `Cref`, вычисленным на CPU.  
Если все элементы совпадают, программа выводит `Correct = YES`.

## Анализ графика производительности CPU и GPU (Vector Add)
На представленном графике показано сравнение времени выполнения задачи поэлементного сложения массивов (Vector Add) на CPU и GPU для двух размеров входных данных: N = 1 000 000 и N = 10 000 000 элементов. 
По оси X отображены различные сценарии выполнения: 
CPU для малого и большого размера данных, 
GPU - отдельно время выполнения вычислительного ядра (kernel time), 
GPU - общее время выполнения (total time), включающее запуск ядра и копирование результата.

По оси Y отложено время выполнения в миллисекундах.

### Поведение CPU
Для CPU наблюдается ожидаемое линейное увеличение времени выполнения при росте размера данных:
при N = 1 000 000 время составляет менее 1 мс,
при N = 10 000 000 время возрастает до ~11–12 мс.
Это объясняется тем, что последовательная реализация на CPU выполняет операцию сложения элементов поочерёдно, и время работы напрямую зависит от количества элементов массива.

### Поведение GPU (Kernel Time)
В случае GPU kernel time видно, что:
время выполнения ядра остаётся очень малым как для N = 1M, так и для N = 10M, рост размера данных приводит лишь к незначительному увеличению времени.
Это демонстрирует высокую степень параллелизма GPU: большое количество потоков позволяет обрабатывать элементы массива одновременно, что делает время вычислений слабо зависимым от размера задачи.

### Поведение GPU (Total Time)
При анализе GPU total time заметно, что:
общее время значительно выше, чем чистое kernel time, при N = 10 000 000 total time достигает ~30 мс.
Это связано с накладными расходами OpenCL, в частности:
синхронизацией, запуском kernel, копированием данных между памятью устройства и хоста.
Таким образом, при малых и средних размерах данных выигрыш GPU может частично нивелироваться затратами на управление вычислениями и передачу данных.

### Сравнительный вывод
Из графика можно сделать следующие выводы:
GPU значительно быстрее CPU с точки зрения чистых вычислений, что подтверждается малым значением kernel time даже для больших массивов.
Общее время выполнения на GPU может превышать CPU-вариант из-за накладных расходов, особенно при больших объёмах данных.
CPU показывает стабильное и предсказуемое масштабирование, но не может конкурировать с GPU по вычислительной скорости.
GPU наиболее эффективен, когда:
объём вычислений велик,
накладные расходы распределяются на большое число операций.

## Вывод
В результате выполнения двух сценариев было показано, что:
- GPU обеспечивает более высокую производительность при больших объёмах данных,
- при меньших размерах массива выигрыш GPU может быть менее заметен,
- OpenCL позволяет использовать единый код на C++ для выполнения вычислений как на CPU, так и на GPU, что делает подход универсальным и масштабируемым.

Данный эксперимент подтверждает эффективность параллельных вычислений и наглядно демонстрирует различие в производительности CPU и GPU при обработке массивов большого размера.
