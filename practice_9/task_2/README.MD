# Задание 9.2 — Распределённое решение СЛАУ методом Гаусса (MPI) + измерение времени

## Цель
Реализовать распределённое решение системы линейных уравнений `A x = b`
методом Гаусса и исследовать производительность при разных значениях `-np`.

В реализации используются:
- `MPI_Scatter` для распределения строк матрицы и вектора `b` по процессам;
- `MPI_Bcast` для рассылки текущей опорной (pivot) строки на каждом шаге прямого хода;
- `MPI_Gather` для сборки результатов на `rank = 0`;
- `MPI_Wtime()` для измерения общего времени выполнения.

---

## Краткое описание алгоритма
1. На `rank = 0` генерируется матрица `A` размера `N×N` и вектор `b`.
2. Для проверки корректности сначала генерируется `x_true`, затем вычисляется `b = A * x_true`.
3. Строки матрицы распределяются равномерно через `MPI_Scatter` (используется padding, если `N` не делится на число процессов).
4. Прямой ход:
   - на каждом шаге `k` процесс-владелец pivot-строки отправляет её всем процессам через `MPI_Bcast`;
   - каждый процесс обновляет только свои строки (глобальные индексы `> k`).
5. После прямого хода матрица и `b` собираются на `rank = 0` (`MPI_Gather`).
6. Обратный ход выполняется на `rank = 0`, затем сравнивается результат с `x_true`.

---

## Измерение времени
Время выполнения измеряется через `MPI_Wtime()` с синхронизацией процессов:
- `MPI_Barrier` перед стартом таймера;
- `MPI_Barrier` перед остановкой таймера.

Замер включает:
- распределение данных (Scatter),
- прямой ход (вычисления + Bcast),
- сбор результатов (Gather).

---

## Результаты

### N = 128
| MPI processes (-np) | Execution time (s) | Max abs error vs x_true |
|---:|---:|---:|
| 1 | 0.000583 | 0.000000 |
| 2 | 0.001090 | 0.000000 |
| 4 | 0.001968 | 0.000000 |

Пример решения:  
`x[0..4] = 0.313200, 0.555979, 0.938285, 0.736322, 0.192408`

---

### N = 256
| MPI processes (-np) | Execution time (s) | Max abs error vs x_true |
|---:|---:|---:|
| 1 | 0.004467 | 0.000000 |
| 2 | 0.006637 | 0.000000 |
| 4 | 0.012955 | 0.000000 |

Пример решения:  
`x[0..4] = 0.313200, 0.555979, 0.938285, 0.736322, 0.192408`

---

## Анализ производительности
- Корректность подтверждается нулевой ошибкой `Max abs error vs x_true = 0.000000` во всех запусках.
- При увеличении числа процессов время выполнения **увеличивается**, а не уменьшается.
  Это ожидаемо для небольших матриц, потому что:
  - прямой ход требует `MPI_Bcast` на каждом шаге `k`, а таких шагов `N`;
  - для маленьких размеров задачи коммуникационные расходы становятся доминирующими;
  - в среде типа Colab накладные расходы MPI (запуск процессов, синхронизация) сильно заметны.
- При увеличении размера матрицы (128 → 256) время заметно растёт, что соответствует росту вычислительной сложности метода Гаусса.

---

## Вывод
Распределённая реализация метода Гаусса с использованием `MPI_Scatter`, `MPI_Bcast` и `MPI_Gather`
работает корректно при разных `N` и `-np`.

С точки зрения производительности:
- для небольших `N` увеличение числа процессов не даёт ускорения из-за доминирования коммуникаций;
- выигрыш от параллелизма ожидается при более крупных размерах матриц и/или на настоящем кластере с низкими задержками сети.

---

## Команды запуска
```bash
mpicxx -O2 9_2.cpp -o 9_2
mpirun -np 1 ./9_2 128
mpirun -np 2 ./9_2 128
mpirun -np 4 ./9_2 128
mpirun -np 1 ./9_2 256
mpirun -np 2 ./9_2 256
mpirun -np 4 ./9_2 256
