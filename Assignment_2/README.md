# Assignment 2 - OpenMP, CUDA и гетерогенные вычисления

## Описание
Assignment 2 посвящён изучению параллельных вычислений на CPU и GPU с использованием **OpenMP** и **CUDA**, а также принципов **гетерогенной параллелизации**.  
В работе реализованы последовательные и параллельные версии алгоритмов, выполнено сравнение времени выполнения и сделаны выводы.

## Содержание работы

### Задача 1. Введение в гетерогенную параллелизацию (теория)
Рассмотрены:
- что такое гетерогенная параллелизация;
- различия CPU и GPU;
- преимущества гетерогенного подхода;
- примеры реальных приложений.

### Задача 2. Работа с массивами и OpenMP
Программа:
- создаёт массив из **10 000** случайных чисел;
- находит **min/max**:
  - последовательно;
  - параллельно с OpenMP;
- сравнивает время выполнения.

### Задача 3. Параллельная сортировка с OpenMP
Реализована сортировка выбором:
- последовательная версия;
- версия с OpenMP;
- тестирование для массивов **1 000** и **10 000** элементов.

### Задача 4. Сортировка на GPU с использованием CUDA
Реализована параллельная сортировка слиянием на GPU:
- массив делится на подмассивы (каждый блок сортирует свой подмассив);
- выполняются параллельные проходы слияния;
- тестирование для массивов **10 000** и **100 000** элементов.

## Технологии
- C++
- OpenMP
- CUDA
- (для запуска CUDA) Google Colab / ПК с NVIDIA GPU + CUDA Toolkit

## Контрольные вопросы - Assignment 2 (короткие ответы)

#### Что понимается под гетерогенной параллелизацией?
Это распределение вычислений между разными типами устройств (например, CPU и GPU) для ускорения задач.

В чём принципиальные различия архитектур CPU и GPU?
CPU: меньше мощных ядер, подходит для сложной логики. GPU: много простых ядер, подходит для массовых параллельных операций.

Какие задачи лучше подходят для GPU, а какие — для CPU?
GPU: одинаковые операции над большими массивами (матрицы, изображения, ML). CPU: ветвления, управление, сложная логика.

Почему не все алгоритмы эффективно распараллеливаются с OpenMP?
Из-за зависимостей между шагами и накладных расходов на потоки/синхронизацию.

В чём основная идея сортировки слиянием?
Разделить массив на части, отсортировать их и затем слить в один отсортированный массив.

Какие сложности при сортировке слиянием на GPU?
Сложно сделать эффективное параллельное слияние, важно управление памятью и синхронизация.

Как размер блока и сетки влияет на производительность GPU?
Влияет на загрузку GPU и использование ресурсов. Неправильные параметры дают простои или лишние накладные расходы.

Почему гетерогенный подход может быть эффективнее только CPU или только GPU?
CPU делает управление и сложную логику, GPU — массовые вычисления, вместе это даёт лучшую производительность.
